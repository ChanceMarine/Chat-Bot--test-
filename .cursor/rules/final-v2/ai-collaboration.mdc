---
description: Comprehensive AI collaboration patterns, decision frameworks, complexity analysis, task expansion strategies, and research integration
globs: **/*
alwaysApply: true
---
# AI Collaboration Guide: Complete Decision-Making and Task Management System

## Table of Contents
1. [Core Collaboration Principles](#core-collaboration-principles)
2. [Task Complexity Analysis System](#task-complexity-analysis-system)
3. [Task Expansion Strategies](#task-expansion-strategies)
4. [Decision Frameworks](#decision-frameworks)
5. [Research Integration](#research-integration)
6. [Prompting Strategies](#prompting-strategies)
7. [Context Management](#context-management)
8. [Quality Assurance](#quality-assurance)
9. [Performance Optimization](#performance-optimization)
10. [Continuous Learning](#continuous-learning)

---

## Core Collaboration Principles

### Partnership Approach
Work as a skilled team member who can execute independently while maintaining alignment with project goals and user expectations.

### Systematic Decision-Making
Use consistent, repeatable frameworks to make high-quality decisions throughout the development process.

### Intelligent Automation
Leverage AI capabilities to automatically analyze complexity, expand tasks, and optimize workflows while maintaining human oversight.

### Efficient Communication
Minimize unnecessary back-and-forth while ensuring critical validation at key decision points.

### Continuous Improvement
Learn from each interaction and project to improve decision-making accuracy and process effectiveness.
---

##
 Task Complexity Analysis System

### Comprehensive Complexity Scoring Framework (1-10 Scale)

#### Multi-Factor Analysis Criteria

**1. Technical Complexity (40% weight)**
- Algorithm sophistication required (1-10)
- Number of integration points (1-10)
- Data structure complexity (1-10)
- Performance optimization needs (1-10)

**2. Coordination Complexity (25% weight)**
- System dependencies (1-10)
- Team coordination requirements (1-10)
- Cross-functional integration needs (1-10)

**3. Risk Factors (20% weight)**
- Technology maturity and stability (1-10)
- External dependencies reliability (1-10)
- Security implications and requirements (1-10)

**4. Implementation Scope (15% weight)**
- Number of files/components affected (1-10)
- Testing requirements and coverage (1-10)
- Documentation needs and complexity (1-10)

### Complexity Evaluation Matrix

```
Score 1-3 (Low):
- Single component changes
- Well-established patterns
- Minimal dependencies
- Clear implementation path

Score 4-6 (Medium):
- Multiple component integration
- Some new patterns required
- Moderate dependencies
- Standard complexity algorithms

Score 7-8 (High):
- Complex system integration
- Novel approaches required
- High dependency coordination
- Advanced algorithms needed

Score 9-10 (Critical):
- Architectural changes required
- Cutting-edge technology
- Complex dependency chains
- High-risk implementation
```

### Automatic Expansion Triggers
- **Complexity Score ≥ 5**: Flag for potential expansion
- **Multiple Integration Points**: More than 3 external systems
- **High Risk Factors**: Unproven tech or critical security
- **Broad Scope**: Affects more than 5 files/components

---

## Task Expansion Strategies

### Strategy 1: Complexity-Report Driven
Used when detailed complexity analysis has been performed.

### Strategy 2: Research-Driven Expansion
Used when codebase analysis is available.

#### Research Process:
1. **Explore Structure**: Use glob patterns to understand project
2. **Find Patterns**: Search for existing implementations
3. **Analyze Context**: Read key files to understand architecture
4. **Generate Aligned Tasks**: Create subtasks that build on existing patterns

### Strategy 3: Default Systematic Expansion
Standard approach for general task breakdown.

#### Expansion Principles:
1. **Component Boundaries**: Break along logical component lines
2. **Dependency Order**: Sequence subtasks by dependencies
3. **Testing Integration**: Include testing in each subtask
4. **Clear Interfaces**: Define inputs/outputs between subtasks

---

## Decision Frameworks

### Requirements Analysis Framework

**Prioritization Criteria (weighted):**
1. **User Impact Severity (40%)**: Critical → High → Medium → Low
2. **Technical Feasibility (30%)**: Immediate → Moderate → Complex → Uncertain
3. **Dependency Relationships (20%)**: Foundation → Independent → Dependent → Optional
4. **Business Value (10%)**: High ROI → Medium ROI → Low ROI → Experimental

### Design Decision Framework

**Evaluation Matrix:**
| Criteria | Weight | Scoring Guidelines |
|----------|--------|-------------------|
| Maintainability | 30% | Code clarity, separation of concerns, testing ease |
| Scalability | 25% | Performance under load, resource efficiency |
| Reliability | 20% | Error handling, failure recovery, consistency |
| Development Velocity | 15% | Implementation complexity, tooling support |
| Security | 10% | Authentication, data protection, compliance |

### Task Planning Framework

**Decomposition Strategy:**
1. **Incremental Value**: Each subtask delivers testable functionality
2. **Dependency Management**: Minimize blocking dependencies
3. **Risk Mitigation**: Address high-risk areas early
4. **Complexity Balance**: Mix simple and complex subtasks

---

## Research Integration

### Codebase Analysis Process
1. **Explore Structure**: Use file exploration to understand project layout
2. **Find Patterns**: Search for existing implementations and approaches
3. **Analyze Architecture**: Understand current design patterns and conventions
4. **Identify Reusable Components**: Find existing code that can be leveraged
5. **Plan Integration**: Design subtasks that integrate smoothly

### Context-Aware Development
- **Build on Existing Patterns**: Create tasks that align with current architecture
- **Leverage Components**: Reuse and extend existing functionality
- **Follow Conventions**: Maintain consistency with existing code
- **Avoid Duplication**: Check for existing functionality before creating new
- **Consider Integration**: Ensure tasks integrate smoothly with existing systems---


## Prompting Strategies

### Core Prompting Principles

#### 1. Context-Rich Prompts
Always provide comprehensive context:
- **Project Background**: Type of application, target users, business goals
- **Technical Context**: Current technology stack, architecture, constraints
- **Business Context**: User needs, success criteria, timeline considerations
- **Integration Context**: Existing systems, data sources, external dependencies

#### 2. Phase-Specific Prompts
Clearly specify which phase you're in:
- **Requirements**: "Let's start with requirements gathering for [feature]"
- **Design**: "Now let's design the solution based on these requirements"
- **Tasks**: "Break down this design into actionable implementation tasks"

#### 3. Structured Input Patterns
Organize complex requests logically:
- **Core Functionality First**: Essential features before nice-to-have additions
- **Incremental Complexity**: Build understanding progressively
- **Clear Priorities**: Distinguish between must-have and optional features

### Effective Prompt Templates

#### Requirements Phase Prompts
```
I want to create a spec for [FEATURE_NAME]. Here's the context:

Project: [PROJECT_TYPE] for [TARGET_USERS]
Platform: [MOBILE/WEB/DESKTOP/API]
Technology: [CURRENT_TECH_STACK or "To be determined"]
Business Goal: [PRIMARY_OBJECTIVE]
Constraints: [TECHNICAL_AND_BUSINESS_CONSTRAINTS]

The feature should [CORE_FUNCTIONALITY] and integrate with [EXISTING_SYSTEMS].

Please create comprehensive requirements using EARS format, covering:
- Core user stories with clear value propositions
- Detailed acceptance criteria for each story
- Edge cases and error scenarios
- Integration requirements with existing systems
- Performance and security considerations
```

#### Design Phase Prompts
```
Based on the approved requirements, create a comprehensive design for [FEATURE_NAME].

Requirements Summary: [KEY_REQUIREMENTS_RECAP]

Please design a solution that addresses:
- Overall system architecture and component relationships
- Detailed data models and their relationships
- API interfaces and contracts (if applicable)
- Error handling strategies and recovery mechanisms
- Comprehensive testing approach
- Performance optimization strategies
- Security implementation details

Consider these constraints:
- Platform: [TARGET_PLATFORM]
- Technology Preferences: [PREFERRED_TECHNOLOGIES or "Best practices for platform"]
- Performance Requirements: [PERFORMANCE_NEEDS]
- Integration Points: [SYSTEMS_TO_INTEGRATE]
- Security Requirements: [SECURITY_NEEDS]
- Scalability Considerations: [GROWTH_EXPECTATIONS]
```

#### Tasks Phase Prompts
```
Now that the design is approved, break it down into actionable implementation tasks.

Design Summary: [KEY_DESIGN_COMPONENTS]

Create an implementation plan that:
- Follows incremental development with early validation
- Includes complexity analysis for each task
- Expands complex tasks (≥5) into manageable subtasks
- Sequences tasks to minimize dependencies
- Includes comprehensive testing for each task
- Provides specific deliverables and acceptance criteria

Each task should:
- Reference specific requirements it addresses
- Be completable by a development team
- Build incrementally on previous tasks
- Include detailed testing considerations
- Have clear acceptance criteria

Consider:
- Platform: [TARGET_PLATFORM]
- Team Experience Level: [TEAM_SKILL_LEVEL]
- Timeline Constraints: [PROJECT_TIMELINE]
- Risk Tolerance: [ACCEPTABLE_RISK_LEVEL]
- Quality Requirements: [QUALITY_STANDARDS]
```

### Advanced Prompting Techniques

#### Progressive Disclosure
Build understanding incrementally:
1. "First, let's identify the main user stories for this feature"
2. "Now, let's add detailed acceptance criteria for each story"
3. "Next, let's consider edge cases and error scenarios"
4. "Finally, let's analyze complexity and expand complex tasks"

#### Alternative Exploration
When facing complex decisions:
```
Show me 2-3 different approaches for [PROBLEM] on [PLATFORM].
For each approach, include:
- Pros and cons analysis
- Implementation complexity assessment
- Platform-specific considerations
- Performance implications
- Maintenance considerations
- Integration requirements

Which approach best aligns with [SPECIFIC_CRITERIA]?
```

#### Complexity Analysis Prompts
```
Analyze this task for complexity using the 1-10 scale:
- Technical complexity: [algorithms, integrations, data structures]
- Coordination complexity: [dependencies, team coordination]
- Risk factors: [unproven tech, external dependencies]
- Implementation scope: [files affected, testing needs]

If complexity ≥ 5, expand into 3-8 subtasks with clear boundaries.
Consider the platform: [PLATFORM] and technology: [TECH_STACK]
```

#### Research-Driven Prompts
```
Before expanding this task, analyze the existing codebase:
1. Explore project structure with appropriate patterns for [PLATFORM]
2. Search for similar implementations
3. Understand current architecture and patterns
4. Generate subtasks that align with existing code

Create subtasks that build upon rather than duplicate existing work.
Focus on [PLATFORM]-specific best practices and patterns.
```

---

## Context Management

### Project Context Tracking
- **Platform Type**: Mobile, Web, Desktop, API, etc.
- **Technology Stack**: Current or preferred technologies
- **Architecture Patterns**: Existing architectural decisions
- **Team Capabilities**: Skill levels and experience
- **Business Constraints**: Timeline, budget, compliance requirements

### Dynamic Context Updates
- **Technology Evolution**: Update context as technology choices are made
- **Requirement Changes**: Adjust context when requirements evolve
- **Implementation Discoveries**: Update based on development findings
- **Team Changes**: Adjust for team skill level changes

### Context-Aware Decision Making
- **Platform-Specific Guidance**: Adapt advice to target platform
- **Technology-Appropriate Solutions**: Suggest solutions that fit the tech stack
- **Skill-Level Appropriate Tasks**: Match task complexity to team capabilities
- **Business-Aligned Priorities**: Prioritize based on business constraints

---

## Quality Assurance

### Expansion Validation
- **Coverage Check**: All original task functionality covered by subtasks
- **Dependency Validation**: Subtask dependencies are logical and minimal
- **Boundary Clarity**: Clear interfaces between subtasks
- **Testing Integration**: Each subtask includes validation criteria

### Complexity Accuracy
- **Historical Tracking**: Compare predicted vs actual complexity
- **Adjustment Learning**: Improve scoring based on implementation reality
- **Team Calibration**: Adjust thresholds based on team capabilities
- **Platform Considerations**: Account for platform-specific complexity factors

### Decision Quality Metrics
- **Decision Consistency**: Consistent application of decision frameworks
- **Outcome Tracking**: Monitor results of decisions made
- **Feedback Integration**: Incorporate feedback to improve decision-making
- **Continuous Calibration**: Adjust frameworks based on effectiveness

---

## Performance Optimization

### Analysis Performance
- **Rapid Complexity Assessment**: Quick but accurate complexity scoring
- **Efficient Research**: Streamlined codebase analysis processes
- **Smart Caching**: Cache analysis results for similar tasks
- **Parallel Processing**: Analyze multiple aspects simultaneously

### Decision Speed vs Quality
- **Time-Boxed Analysis**: Set appropriate time limits for analysis depth
- **Progressive Refinement**: Start with quick analysis, refine as needed
- **Risk-Based Depth**: Deeper analysis for higher-risk decisions
- **Confidence Thresholds**: Minimum confidence levels for different decision types

### Scalability Considerations
- **Large Codebase Handling**: Efficient analysis of large projects
- **Multiple Platform Support**: Handle diverse technology stacks
- **Team Scaling**: Support for larger development teams
- **Project Complexity Growth**: Handle increasing project complexity over time

---

## Continuous Learning

### Pattern Recognition
- **Recurring Issues**: Identify common problems and solutions
- **Successful Patterns**: Recognize effective approaches and techniques
- **Platform-Specific Insights**: Learn platform-specific best practices
- **Technology Trends**: Stay current with evolving technologies

### Feedback Integration
- **User Feedback**: Incorporate feedback on decision quality and effectiveness
- **Implementation Results**: Learn from actual implementation outcomes
- **Team Input**: Gather insights from development team experiences
- **Performance Metrics**: Use quantitative metrics to guide improvements

### Knowledge Base Evolution
- **Best Practice Updates**: Continuously update best practices
- **New Technology Integration**: Incorporate new technologies and approaches
- **Process Refinement**: Improve processes based on experience
- **Quality Enhancement**: Continuously improve decision quality

### Self-Improvement Mechanisms
- **Automated Learning**: Automatically learn from patterns and outcomes
- **Feedback Loops**: Systematic feedback collection and integration
- **Performance Monitoring**: Track and improve decision-making performance
- **Adaptive Thresholds**: Adjust complexity and decision thresholds based on results

This comprehensive AI collaboration system provides intelligent, context-aware decision-making and task management that adapts to any platform or technology while continuously improving through experience and feedback.